[2023년 9월 13일]
1. Pylon alley로 경로 변경하는 법 찾음 - IPG 기존 충돌 4회였는데 3회로 변경
 -> 이 방식이 당연하지만 합리적임
 -> 그렇다면 RL의 경로는 무엇을 주어야 하는가..?
 -> 현재 방식: 콘을 세워두고 사이를 통과하지 못할 경우 벌점을 주는 방식
 -> 경로를 변경해야 하는 부분에서 콘 사이 간격이 넓어지다 보니 오히려 안좋은 결과를 보임
2. Github 생성: Road, src_cm4sl, 파이썬 코드
3. 궁금한 점: state에 해당 시간 대의 ipg와 rl의 state(alHori 같은 것)를 동시에 주고, rl이 안좋을 때 리워드를 주는 식으로 했더니 학습이 안됨
4. 


직진하라하고 중간에 콘 놓고 부딪히면 패널티
--------
1. Hierarchical reinforcement learning
2. CNN 회전시키는거
3. 
--------
[0925]
1. 연구 동기를 어떤식으로 잡아가고, 목표를 어떤식으로 설정해야하는지
2. 앞으로 방향성
 - equivariant neural network
 - 뒤에 휠 돌아가는거


_steup_sim 에서 시뮬링크 실행 전에
self.eng. ~~  .m파일 실행하는 코드 넣으면 됨.

결과 내보고 nn이랑 라그랑지안 각각 해보고 합치는 방향으로
----------
[0926]
1. hierarchical rl먼저
박재현 논문 - distributed
파이디는 6개 조인트 중 어떤 관절을 움직일지 결정 - policy a
파이씨에서는 각각의 관절을 얼마만큼 움직일지 - policy b
파이로우만 따로 학습 시킴. 조인트를 어떻게 움직일지 - policy c

policy b를 시작을 해야함.
당장 쓰기는 어려우니 policy c는 test function
policy b가 train을 할거임.
bezier curve가 곡선 만드는 코드
센터라인이 path를 기준으로 벗어나지 않게
5.2 전에 있는 리워드 활용해서
(임재현)distributional and ~







