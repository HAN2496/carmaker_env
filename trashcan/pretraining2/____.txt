x[Meta-Controller]
1. 정해진 지령이 있어야 함. 콘을 기준으로 왼쪽으로 가라고 하던지, 콘을 기준으로 오른쪽으로 가라고 하던지. 직진을 하라고 하던지.
2. 어느타이밍에 어떠한 제시를 할지는 학습되어야 함.
3. ㅁㄴ러ㅣㄴㄹㄴㅇㄹ

----
[policy b와 a의 역할]
policy a
- 직진인지 / 회전인지
- kappa 값을 결정해준다고 보는게 좋을 듯.

policy b
-a가 정해준 kappa값을 잘 따라가도록 학습

----
policy a, b의 최종적인 목표가 무엇인가?
 -> 좋은 경로. 그렇다면 좋은 경로란?
1. 최단시간 경로
2. 기하학적으로 좀 더 깔끔한 경로.

State는?
1. 전방 cone 데이터. 앞으로는, cone과 차선을 동일한 개념으로 학습을 시켜야할 듯.

문제는?
1. 전방 cone 데이터 안에 들어오는 점이면 어떠한 상황이어도 동일하다는 것.
 -> sparse한 리워드 발생.

해결법은?
1. kappa값을 a가 결정해준다.
2. 아니면, 함수를 제작한다. 직선, 3차원 곡선, 원. 세 개 정도?

구상은?
1. policy b
 - state로 전방 cone 데이터, kappa값 (결정되어있음)
---
.npz
stable baselinse3 expert data - pre-Training (Behavior Cloning)
.pretrain
